# app/utils/web_retriever.py

import requests
from bs4 import BeautifulSoup
from utils.gemini_url_resolver import resolve_link_via_gemini


def get_rbi_latest_circulars(limit=5):
    url = "https://www.rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        circulars = []
        for link in soup.select(".pressrelease li a")[:limit]:
            title = link.get_text(strip=True)
            href = link.get("href")
            full_url = f"https://www.rbi.org.in{href}"
            circulars.append((title, full_url))

        return circulars
    except Exception as e:
        return [("‚ö†Ô∏è Failed to retrieve RBI circulars", str(e))]


def get_hdfc_credit_cards(limit=5):
    # ‚úÖ Gemini URL resolution first
    try:
        gemini_result = resolve_link_via_gemini("List HDFC credit cards")
        if "http" in gemini_result:
            return [gemini_result]  # Return as a list for consistency
    except:
        pass

    # üßæ Then fallback to scraping
    url = "https://www.hdfcbank.com/personal/pay/cards/credit-cards"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        cards = []
        for card_div in soup.select(".card-name")[:limit]:
            name = card_div.get_text(strip=True)
            cards.append(name)

        if not cards:
            cards.append("‚ö†Ô∏è Could not find card names. Structure might have changed.")

        return cards
    except Exception as e:
        return [f"‚ö†Ô∏è Failed to retrieve HDFC credit cards: {e}"]


def get_rbi_interest_rates():
    try:
        gemini_result = resolve_link_via_gemini("RBI interest rate table")
        if "http" in gemini_result:
            return {"üîó Gemini-Suggested RBI Rates Link": gemini_result}
    except:
        pass

    url = "https://www.rbi.org.in/home.aspx"
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, "html.parser")

        rates = {}
        for row in soup.select(".rr_data tr"):
            cols = row.find_all("td")
            if len(cols) >= 2:
                label = cols[0].get_text(strip=True)
                value = cols[1].get_text(strip=True)
                rates[label] = value

        return rates if rates else {"‚ö†Ô∏è": "No rates found. RBI homepage structure may have changed."}
    except Exception as e:
        return {"‚ö†Ô∏è Error": str(e)}


def format_circulars(circulars):
    return "\n".join([f"- [{title}]({url})" for title, url in circulars])


def format_credit_cards(cards):
    return "\n".join([f"- {name}" for name in cards])


def format_interest_rates(rates):
    return "\n".join([f"- {k}: {v}" for k, v in rates.items()])
