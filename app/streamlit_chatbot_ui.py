import streamlit as st
import pandas as pd

from utils.session_manager import load_user_session
from utils.context_tracker import update_context_with_memory
from utils.response_generator import generate_final_answer
from utils.cache_manager import GlobalCache, is_public_query
from utils.rag_engine import load_documents_for_use_case
from utils.agent_orchestrator import orchestrate_agents

st.set_page_config(page_title="ğŸ’¬ HDFC Banking Chatbot", layout="wide")

st.title("ğŸ¦ HDFC Banking Assistant (RAG + Web + Agents + Cache)")
st.markdown("Ask your banking-related queries. This assistant combines document search, agents, real-time web data, and cache.")

# --- User Login ---
user_id = st.sidebar.text_input("ğŸ‘¤ Enter User ID", value="001")

if user_id and "session_data" not in st.session_state:
    session, greeting = load_user_session(user_id)
    if session:
        st.session_state.session_data = session
        st.session_state.chat_history = []
        st.success(greeting)
    else:
        st.error(greeting)

# --- Chat Input ---
if "session_data" in st.session_state:
    query = st.chat_input("Ask me anything...")

    if query:
        session = st.session_state.session_data

        # Step 1: Intent + Use Case
        intent, use_case = update_context_with_memory(query, session)

        # Step 2: Global Cache Check
        final_response = None
        source = ""
        if is_public_query(intent, use_case):
            cached = GlobalCache.get(query)
            if cached:
                final_response = cached
                source = "ğŸ§  Served from Cache"

        # Step 3: Agent Orchestration or RAG fallback
        if not final_response:
            try:
                result = orchestrate_agents(query, use_case, user_name=session["name"])

                if result == "NO_OP":
                    # Use RAG fallback for non-agent queries
                    context = load_documents_for_use_case(use_case)
                    final_response = generate_final_answer(query, context, session["name"])
                    source = "ğŸ“„ Served from RAG Docs"
                else:
                    final_response = result
                    source = "ğŸ¤– Generated by Agent Pipeline"

            except Exception as e:
                final_response = f"âš ï¸ Agent failure: {e}"
                source = "âŒ Error"

        # Step 4: Store in memory
        st.session_state.chat_history.append({
            "query": query,
            "intent": intent,
            "use_case": use_case,
            "response": final_response,
            "source": source
        })
        session["memory"].append(st.session_state.chat_history[-1])

# --- Display Chat History ---
if "chat_history" in st.session_state:
    for item in st.session_state.chat_history:
        with st.chat_message("user"):
            st.write(item["query"])
        with st.chat_message("assistant"):
            st.markdown(item["response"])
            st.caption(item.get("source", ""))
